{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6S2HVAkSt0p"
      },
      "source": [
        " # CIFAR-10 Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1mzy2J8_nc1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3EXwoz-KHtWO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\PMLS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Gs6Lyc_pd0"
      },
      "source": [
        "## Load and prepare the dataset\n",
        "\n",
        "The [CIFAR 10](https://www.tensorflow.org/datasets/catalog/cifar10) dataset already has train and test splits and you can use those in this exercise. Here are the general steps:\n",
        "\n",
        "* Load the train/test split from TFDS. Set `as_supervised` to `True` so it will be convenient to use the preprocessing function we provided.\n",
        "* Normalize the pixel values to the range [0,1], then return `image, image` pairs for training instead of `image, label`. This is because you will check if the output image is successfully regenerated after going through your autoencoder.\n",
        "* Shuffle and batch the train set. Batch the test set (no need to shuffle).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9F7YsCNIKSA"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "\n",
        "def map_image(image , label):\n",
        "\n",
        "    image = tf.cast(image , dtype = tf.float32)\n",
        "\n",
        "    image = image / 255.0\n",
        "\n",
        "    return image , image\n",
        "\n",
        "# Parameters for data\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "SHUFFLE_BUFFER_SIZE = 1024\n",
        "\n",
        "train_dataset = tfds.load('cifar10' , as_supervised= True , split = 'train' )\n",
        "\n",
        "test_dataset = tfds.load('cifar10' , as_supervised= True , split = 'test' )\n",
        "\n",
        "# Preprocess both the datasets\n",
        "\n",
        "train_dataset = train_dataset.map(map_image)\n",
        "\n",
        "test_dataset = test_dataset.map(map_image)\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = test_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyOgGJs_t98"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr-Bok3lRgA3"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D , UpSampling2D , MaxPooling2D , Input\n",
        "\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3,))\n",
        "\n",
        "# Encoder layers\n",
        "\n",
        "conv_1 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
        "\n",
        "max_pool_1 = MaxPooling2D(pool_size=(2,2))(conv_1)\n",
        "\n",
        "conv_2 = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(max_pool_1)\n",
        "\n",
        "max_pool_2 = MaxPooling2D(pool_size=(2,2))(conv_2)\n",
        "\n",
        "# Bottle neck layer\n",
        "\n",
        "bottle_neck = Conv2D(filters = 256 , kernel_size = (3 , 3) , activation = 'relu' , padding = \"same\")(max_pool_2)\n",
        "\n",
        "# Decoder layers\n",
        "\n",
        "conv_3 = Conv2D(filters = 128 , kernel_size = ( 3 , 3 ) , activation = 'relu' , padding = 'same')(bottle_neck)\n",
        "\n",
        "up_sample_1 = UpSampling2D(size = ( 2 , 2 ))(conv_3)\n",
        "\n",
        "conv_4 = Conv2D( filters = 64 , kernel_size = ( 3 , 3 ) , activation = 'relu' , padding = 'same' )(up_sample_1)\n",
        "\n",
        "up_sample_2 = UpSampling2D(size = ( 2 , 2))(conv_4)\n",
        "\n",
        "decoder_output = Conv2D(filters = 3 , kernel_size= ( 3 , 3) , activation = 'sigmoid' , padding = 'same')(up_sample_2)\n",
        "\n",
        "model = tf.keras.Model(inputs =inputs, outputs=decoder_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRWTAijKEVUC"
      },
      "source": [
        "## Configure training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHIeD9eDETSk"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLQPhm1W_8dC"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMBimOnsRvg0"
      },
      "outputs": [],
      "source": [
        "train_steps = len(train_dataset) // 64\n",
        "val_steps = len(test_dataset) // 64\n",
        "\n",
        "### START CODE HERE ###\n",
        "model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=test_dataset, validation_steps=val_steps, epochs=100)\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT2l1c-SAaF4"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFncgqahSQhA"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_dataset, steps=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvw0HLY2kV3w"
      },
      "source": [
        "## Save the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULCfGHEKkaO0"
      },
      "outputs": [],
      "source": [
        "# Save the model you just trained\n",
        "model.save(\"temp_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
